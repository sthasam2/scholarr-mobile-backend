{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today  coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0                      @kconsidder You never tweet  \n",
       "1         0                 Sick today  coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
       "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
       "4         0  @MrKinetik Not a thing!!!  I don't really have..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=500000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/DfFittedVectorizer.sav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "words_df.head()\n",
    "joblib.dump(vectorizer, 'trained_models/DfFittedVectorizer.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = df.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 s, sys: 0 ns, total: 42.6 s\n",
      "Wall time: 42.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, max_iter=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/LogRegForSentimentAnalysis.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export trained model\n",
    "joblib.dump(logreg, \"trained_models/LogRegForSentimentAnalysis.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 923 ms, sys: 108 µs, total: 923 ms\n",
      "Wall time: 921 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/NaiBayesForSentimentAnalysis.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export trained model\n",
    "joblib.dump(bayes, \"trained_models/NaiBayesForSentimentAnalysis.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dont know what to think about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That was fucking awesome dawg!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goddamn what a miracle!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Son of a bitch!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content\n",
       "0  I dont know what to think about it\n",
       "1      That was fucking awesome dawg!\n",
       "2             Goddamn what a miracle!\n",
       "3                     Son of a bitch!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "unknown = pd.DataFrame({'content': [\n",
    "    \"I dont know what to think about it\",\n",
    "    \"That was fucking awesome dawg!\",\n",
    "    \"Goddamn what a miracle!\",\n",
    "    \"Son of a bitch!\"\n",
    "]})\n",
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '100' '11' '12' '15' '1st' '20' '2day' '2nd' '30' 'able' 'about'\n",
      " 'absolutely' 'account' 'actually' 'add' 'after' 'afternoon' 'again' 'ago'\n",
      " 'agree' 'ah' 'ahh' 'ahhh' 'air' 'airport' 'album' 'all' 'almost' 'alone'\n",
      " 'along' 'alot' 'already' 'alright' 'also' 'although' 'always' 'am'\n",
      " 'amazing' 'amp' 'an' 'and' 'annoying' 'another' 'answer' 'any' 'anymore'\n",
      " 'anyone' 'anything' 'anyway' 'app' 'apparently' 'apple' 'are' 'aren'\n",
      " 'around' 'as' 'ask' 'asleep' 'ass' 'at' 'ate' 'aw' 'awake' 'awards'\n",
      " 'away' 'awesome' 'aww' 'awww' 'babe' 'baby' 'back' 'bad' 'band' 'bbq'\n",
      " 'bday' 'be' 'beach' 'beat' 'beautiful' 'because' 'bed' 'been' 'beer'\n",
      " 'before' 'behind' 'being' 'believe' 'best' 'bet' 'better' 'big' 'bike'\n",
      " 'birthday' 'bit' 'black' 'blip' 'blog' 'blue' 'body' 'boo' 'book' 'books'\n",
      " 'bored' 'boring' 'both' 'bought' 'bout' 'box' 'boy' 'boyfriend' 'boys'\n",
      " 'break' 'breakfast' 'bring' 'bro' 'broke' 'broken' 'brother' 'brothers'\n",
      " 'btw' 'bus' 'business' 'busy' 'but' 'buy' 'by' 'bye' 'cake' 'call'\n",
      " 'called' 'came' 'camera' 'can' 'cannot' 'cant' 'car' 'card' 'care' 'case'\n",
      " 'cat' 'catch' 'cause' 'cd' 'chance' 'change' 'chat' 'check' 'chicken'\n",
      " 'chocolate' 'church' 'city' 'class' 'clean' 'cleaning' 'close' 'clothes'\n",
      " 'club' 'coffee' 'cold' 'college' 'com' 'come' 'comes' 'coming' 'company'\n",
      " 'completely' 'computer' 'concert' 'congrats' 'cool' 'cos' 'could'\n",
      " 'couldn' 'couple' 'course' 'crap' 'crazy' 'cream' 'cry' 'crying' 'cup'\n",
      " 'cut' 'cute' 'cuz' 'da' 'dad' 'damn' 'dance' 'date' 'daughter' 'david'\n",
      " 'day' 'days' 'ddlovato' 'dead' 'dear' 'decided' 'definitely' 'did' 'didn'\n",
      " 'didnt' 'die' 'died' 'different' 'dinner' 'dm' 'do' 'does' 'doesn'\n",
      " 'doesnt' 'dog' 'doing' 'don' 'done' 'dont' 'down' 'download' 'dream'\n",
      " 'dreams' 'dress' 'drink' 'drinking' 'drive' 'driving' 'drunk' 'dude'\n",
      " 'due' 'during' 'each' 'earlier' 'early' 'easy' 'eat' 'eating' 'eh'\n",
      " 'either' 'else' 'em' 'email' 'end' 'english' 'enjoy' 'enjoyed' 'enjoying'\n",
      " 'enough' 'episode' 'especially' 'even' 'evening' 'ever' 'every'\n",
      " 'everybody' 'everyone' 'everything' 'exactly' 'exam' 'exams' 'except'\n",
      " 'excited' 'exciting' 'eye' 'eyes' 'face' 'facebook' 'fact' 'fail' 'fair'\n",
      " 'fall' 'family' 'fan' 'fans' 'far' 'fast' 'favorite' 'fb' 'feel'\n",
      " 'feeling' 'feels' 'feet' 'fell' 'felt' 'few' 'ff' 'figure' 'film' 'final'\n",
      " 'finally' 'finals' 'find' 'fine' 'finish' 'finished' 'first' 'fix'\n",
      " 'flight' 'flu' 'fm' 'follow' 'followers' 'followfriday' 'following'\n",
      " 'food' 'for' 'forever' 'forget' 'forgot' 'forward' 'found' 'free'\n",
      " 'french' 'friday' 'friend' 'friends' 'from' 'front' 'fuck' 'fucking'\n",
      " 'full' 'fun' 'funny' 'game' 'games' 'garden' 'gave' 'gd' 'get' 'gets'\n",
      " 'gettin' 'getting' 'girl' 'girls' 'give' 'giving' 'glad' 'go' 'god'\n",
      " 'goes' 'goin' 'going' 'gone' 'gonna' 'good' 'goodbye' 'goodnight'\n",
      " 'google' 'gorgeous' 'got' 'gotta' 'graduation' 'great' 'green' 'gt'\n",
      " 'guess' 'guitar' 'guy' 'guys' 'gym' 'ha' 'had' 'haha' 'hahah' 'hahaha'\n",
      " 'hair' 'half' 'hand' 'hang' 'hanging' 'happen' 'happened' 'happens'\n",
      " 'happy' 'hard' 'has' 'hate' 'hates' 'have' 'haven' 'havent' 'having' 'he'\n",
      " 'head' 'headache' 'heading' 'hear' 'heard' 'heart' 'hehe' 'hell' 'hello'\n",
      " 'help' 'her' 'here' 'hey' 'hi' 'high' 'him' 'his' 'hit' 'hmm' 'hmmm'\n",
      " 'holiday' 'home' 'homework' 'hope' 'hopefully' 'hoping' 'horrible'\n",
      " 'hospital' 'hot' 'hour' 'hours' 'house' 'how' 'http' 'hubby' 'hug' 'huge'\n",
      " 'hugs' 'hungry' 'hurt' 'hurts' 'ice' 'idea' 'idk' 'if' 'ill' 'im' 'in'\n",
      " 'inside' 'instead' 'interesting' 'internet' 'into' 'iphone' 'ipod' 'is'\n",
      " 'isn' 'isnt' 'it' 'its' 'ive' 'jealous' 'job' 'join' 'jonas'\n",
      " 'jonasbrothers' 'july' 'june' 'jus' 'just' 'keep' 'keeps' 'kid' 'kids'\n",
      " 'kill' 'kind' 'kinda' 'knew' 'know' 'knows' 'la' 'lady' 'lakers' 'lame'\n",
      " 'laptop' 'last' 'late' 'later' 'laugh' 'lazy' 'learn' 'least' 'leave'\n",
      " 'leaving' 'left' 'less' 'let' 'lets' 'life' 'like' 'liked' 'lil' 'line'\n",
      " 'link' 'list' 'listen' 'listening' 'little' 'live' 'living' 'll' 'lmao'\n",
      " 'lol' 'london' 'lonely' 'long' 'longer' 'look' 'looked' 'looking' 'looks'\n",
      " 'lose' 'lost' 'lot' 'lots' 'love' 'loved' 'lovely' 'loves' 'loving' 'lt'\n",
      " 'luck' 'lucky' 'lunch' 'luv' 'ly' 'ma' 'mac' 'mad' 'made' 'mail' 'make'\n",
      " 'makes' 'making' 'man' 'many' 'may' 'maybe' 'me' 'mean' 'means' 'meant'\n",
      " 'meet' 'meeting' 'message' 'met' 'might' 'miley' 'mileycyrus' 'mind'\n",
      " 'mine' 'minute' 'minutes' 'miss' 'missed' 'missing' 'mom' 'moment'\n",
      " 'monday' 'money' 'month' 'months' 'mood' 'moon' 'more' 'morning' 'most'\n",
      " 'mother' 'mothers' 'move' 'movie' 'movies' 'moving' 'mr' 'mtv' 'much'\n",
      " 'mum' 'music' 'must' 'my' 'myself' 'myspace' 'name' 'nap' 'near' 'need'\n",
      " 'needed' 'needs' 'never' 'new' 'news' 'next' 'nice' 'night' 'nite' 'no'\n",
      " 'nope' 'not' 'nothing' 'now' 'number' 'of' 'off' 'office' 'officially'\n",
      " 'oh' 'ok' 'okay' 'old' 'omg' 'on' 'once' 'one' 'ones' 'online' 'only'\n",
      " 'open' 'or' 'order' 'other' 'ouch' 'our' 'out' 'outside' 'over' 'own'\n",
      " 'packing' 'page' 'pain' 'paper' 'parents' 'park' 'part' 'party' 'pass'\n",
      " 'past' 'pay' 'people' 'perfect' 'person' 'phone' 'photo' 'photos' 'pic'\n",
      " 'pick' 'pics' 'picture' 'pictures' 'pink' 'pizza' 'place' 'plan' 'plans'\n",
      " 'play' 'played' 'playing' 'please' 'plurk' 'plus' 'point' 'pool' 'poor'\n",
      " 'post' 'power' 'ppl' 'pretty' 'probably' 'problem' 'profile' 'project'\n",
      " 'proud' 'put' 'question' 'quite' 'quot' 'radio' 'rain' 'raining' 'rainy'\n",
      " 'random' 'rather' 're' 'read' 'reading' 'ready' 'real' 'realized'\n",
      " 'really' 'reason' 'red' 'relaxing' 'remember' 'reply' 'rest' 'revision'\n",
      " 'ride' 'right' 'road' 'rock' 'room' 'run' 'running' 'sad' 'sadly' 'safe'\n",
      " 'said' 'same' 'sat' 'saturday' 'save' 'saw' 'say' 'saying' 'says'\n",
      " 'scared' 'scary' 'school' 'season' 'second' 'see' 'seeing' 'seem' 'seems'\n",
      " 'seen' 'send' 'sent' 'seriously' 'service' 'set' 'shall' 'shame' 'share'\n",
      " 'she' 'shirt' 'shit' 'shoes' 'shop' 'shopping' 'short' 'should' 'show'\n",
      " 'shower' 'shows' 'sick' 'side' 'sigh' 'sign' 'sims' 'since' 'sister'\n",
      " 'sit' 'site' 'sitting' 'sleep' 'sleeping' 'sleepy' 'slept' 'slow' 'small'\n",
      " 'smile' 'so' 'sold' 'some' 'someone' 'something' 'sometimes' 'son' 'song'\n",
      " 'songs' 'soo' 'soon' 'sooo' 'soooo' 'sore' 'sorry' 'sound' 'sounds'\n",
      " 'special' 'spend' 'spent' 'star' 'start' 'started' 'starting' 'starts'\n",
      " 'stay' 'still' 'stomach' 'stop' 'store' 'story' 'stuck' 'study'\n",
      " 'studying' 'stuff' 'stupid' 'such' 'suck' 'sucks' 'summer' 'sun' 'sunday'\n",
      " 'sunny' 'sunshine' 'super' 'support' 'supposed' 'sure' 'sweet' 'take'\n",
      " 'taken' 'taking' 'talk' 'talking' 'tea' 'team' 'tell' 'terrible' 'test'\n",
      " 'text' 'than' 'thank' 'thanks' 'that' 'thats' 'the' 'their' 'them' 'then'\n",
      " 'there' 'these' 'they' 'thing' 'things' 'think' 'thinking' 'thinks'\n",
      " 'this' 'tho' 'those' 'though' 'thought' 'three' 'throat' 'through'\n",
      " 'thursday' 'thx' 'tickets' 'til' 'till' 'time' 'times' 'tinyurl' 'tired'\n",
      " 'to' 'today' 'together' 'told' 'tom' 'tommcfly' 'tomorrow' 'tonight'\n",
      " 'too' 'took' 'top' 'totally' 'tour' 'town' 'train' 'tried' 'trip' 'true'\n",
      " 'try' 'trying' 'tuesday' 'tummy' 'turn' 'turned' 'tv' 'tweet' 'tweeting'\n",
      " 'tweets' 'twilight' 'twitpic' 'twitter' 'two' 'ugh' 'uk' 'under'\n",
      " 'understand' 'unfortunately' 'until' 'up' 'update' 'updates' 'upset' 'ur'\n",
      " 'us' 'use' 'used' 'using' 'vacation' 've' 'very' 'via' 'video' 'visit'\n",
      " 'voice' 'vote' 'wait' 'waiting' 'wake' 'waking' 'walk' 'wanna' 'want'\n",
      " 'wanted' 'wants' 'warm' 'was' 'wasn' 'watch' 'watched' 'watching' 'water'\n",
      " 'way' 'we' 'wear' 'weather' 'website' 'wedding' 'wednesday' 'week'\n",
      " 'weekend' 'weeks' 'weird' 'welcome' 'well' 'went' 'were' 'what'\n",
      " 'whatever' 'whats' 'when' 'where' 'which' 'while' 'white' 'who' 'whole'\n",
      " 'why' 'will' 'win' 'wine' 'wish' 'wishes' 'wishing' 'wit' 'with'\n",
      " 'without' 'woke' 'won' 'wonder' 'wonderful' 'wondering' 'wont' 'woo'\n",
      " 'word' 'words' 'work' 'worked' 'working' 'works' 'world' 'worry' 'worse'\n",
      " 'worst' 'worth' 'would' 'wouldn' 'wow' 'write' 'writing' 'wrong' 'wtf'\n",
      " 'www' 'xd' 'xoxo' 'xx' 'xxx' 'ya' 'yay' 'yea' 'yeah' 'year' 'years' 'yep'\n",
      " 'yes' 'yesterday' 'yet' 'yo' 'you' 'your' 'yours' 'yourself' 'youtube'\n",
      " 'yum' 'yummy' 'yup']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sthasam/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>2nd</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100   11   12   15  1st   20  2day  2nd   30  ...  yet   yo  you  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "   your  yours  yourself  youtube  yum  yummy  yup  \n",
       "0   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
       "1   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
       "2   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
       "3   0.0    0.0       0.0      0.0  0.0    0.0  0.0  \n",
       "\n",
       "[4 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it through the vectoriser\n",
    "\n",
    "# transform, not fit_transform, because we already learned all our words\n",
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = pd.DataFrame(unknown_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "unknown_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 ms, sys: 0 ns, total: 18.9 ms\n",
      "Wall time: 18.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict using all our models. \n",
    "\n",
    "# Logistic Regression predictions + probabilities\n",
    "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
    "unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]\n",
    "\n",
    "# Bayes predictions + probabilities\n",
    "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
    "unknown['pred_bayes_proba'] = bayes.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I dont know what to think about it</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That was fucking awesome dawg!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goddamn what a miracle!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Son of a bitch!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672329</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content  pred_logreg  pred_logreg_proba  \\\n",
       "0  I dont know what to think about it            0           0.274998   \n",
       "1      That was fucking awesome dawg!            1           0.745143   \n",
       "2             Goddamn what a miracle!            1           0.589161   \n",
       "3                     Son of a bitch!            1           0.672329   \n",
       "\n",
       "   pred_bayes  pred_bayes_proba  \n",
       "0           0          0.382279  \n",
       "1           1          0.548629  \n",
       "2           1          0.516050  \n",
       "3           1          0.548168  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
